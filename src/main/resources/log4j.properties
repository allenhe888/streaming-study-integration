log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
#log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} [thread:%t] [%c{1}:%L] [%-5p] - %m%n
log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601}[thread:%t][%c{1}:%L][%-5p]  %m%n


log4j.rootLogger=INFO, stdout

# Spark Core 相关类
log4j.logger.org.apache.spark.scheduler=INFO
log4j.logger.org.apache.spark.scheduler.SparkContext=INFO
log4j.logger.org.apache.spark.scheduler.DAGScheduler=WARN
log4j.logger.org.apache.spark.scheduler.TaskSetManager=WARN
log4j.logger.org.apache.spark.scheduler.TaskSchedulerImpl=WARN
log4j.logger.org.apache.spark.ContextCleaner=WARN
log4j.logger.org.apache.spark.executor.Executor=WARN
log4j.logger.org.apache.spark.executor.CoarseGrainedExecutorBackend=INFO
log4j.logger.org.apache.spark.storage.BlockManager=WARN
log4j.logger.org.apache.spark.storage.BlockManagerInfo=WARN
log4j.logger.org.apache.spark.storage.memory.MemoryStore=WARN
log4j.logger.org.apache.spark.broadcast.TorrentBroadcast=WARN


# Spark Streaming相关类
log4j.logger.org.apache.spark.streaming.dstream.DStream=INFO
log4j.logger.org.apache.spark.streaming.scheduler.JobScheduler=WARN
log4j.logger.org.apache.spark.streaming.scheduler.JobGenerator=WARN
log4j.logger.org.apache.spark.streaming.scheduler.ReceivedBlockTracker=WARN
log4j.logger.org.apache.spark.streaming.scheduler.InputInfoTracker=WARN


# RDD级别的类
log4j.logger.org.apache.spark.streaming.kafka010.KafkaRDD=WARN
log4j.logger.org.apache.spark.streaming.kafka010.CachedKafkaConsumer=INFO

# KafkaConsuemr 相关类
log4j.logger.org.apache.kafka.clients.consumer=INFO
log4j.logger.org.apache.kafka.clients.consumer.internals.ConsumerCoordinator=DEBUG
log4j.logger.org.apache.kafka.clients.consumer.internals.Fetcher=INFO
log4j.logger.org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient=INFO

log4j.logger.org.apache.spark.network.protocol.MessageDecoder=INFO
log4j.logger.org.apache.spark.shuffle=INFO

